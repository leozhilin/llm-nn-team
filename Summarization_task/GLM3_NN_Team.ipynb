{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fefb9212-574e-4226-a65f-8e2d0ccb1403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "sum0 = 0\n",
    "sum1 = 0\n",
    "\n",
    "DATA_PATH = './NN.json'\n",
    "PATH_GLOVE_MODEL = '../data/glove.6B.100d.txt'\n",
    "print(\"Loading Glove Model\")\n",
    "f = open(PATH_GLOVE_MODEL, 'r', errors='ignore')\n",
    "GLOVE_MODEL = {}\n",
    "for line in f:\n",
    "    split_lines = line.split()\n",
    "    word = split_lines[0]\n",
    "    word_embedding = np.array([float(value) for value in split_lines[1:]])\n",
    "    GLOVE_MODEL[word] = word_embedding\n",
    "vocab = GLOVE_MODEL.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a767725-f462-4689-83ab-5c1e100da14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11301/11301 [07:27<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1866.3857) tensor(1476.1383)\n",
      "15595.123625516891 4739.562722682953\n",
      "7373 3928\n"
     ]
    }
   ],
   "source": [
    "def generate_allocation_data(sum0, sum1):\n",
    "    Data = {}\n",
    "    with open(DATA_PATH, 'rt', encoding='utf-8') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            sample = json.loads(line.strip())\n",
    "            Data[idx] = sample\n",
    "\n",
    "    rougeScore = ROUGEScore()\n",
    "    total_llm_score, total_nn_score = 0, 0\n",
    "    total_llm_time_cost, total_nn_time_cost = 0, 0\n",
    "\n",
    "    texts = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    llm_time_costs = []\n",
    "    nn_time_costs = []\n",
    "    llm_scores = []\n",
    "    nn_scores = []\n",
    "    for i in trange(len(Data)):\n",
    "        text = Data[i]['input']\n",
    "        ground_truth = Data[i]['ground_truth']\n",
    "        llm_generation = Data[i]['generation']\n",
    "        llm_time_cost = Data[i]['time']\n",
    "        nn_generation = Data[i]['nn_generation']\n",
    "        nn_time_cost = Data[i]['nn_time']\n",
    "        feature = []\n",
    "        for i in (llm_generation + nn_generation).split():\n",
    "            if i in vocab:\n",
    "                feature.append(GLOVE_MODEL[i])\n",
    "        if len(feature) == 0:\n",
    "            continue\n",
    "        feature = np.sum(feature, axis=0)\n",
    "\n",
    "        llm_score = rougeScore(llm_generation, ground_truth)['rougeL_fmeasure']\n",
    "        nn_score = rougeScore(nn_generation, ground_truth)['rougeL_fmeasure']\n",
    "        total_llm_score += llm_score\n",
    "        total_nn_score += nn_score\n",
    "        total_llm_time_cost += llm_time_cost\n",
    "        total_nn_time_cost += nn_time_cost\n",
    "\n",
    "        texts.append(llm_generation + nn_generation)\n",
    "        features.append(feature)\n",
    "        llm_time_costs.append(llm_time_cost)\n",
    "        nn_time_costs.append(nn_time_cost)\n",
    "        llm_scores.append(llm_score)\n",
    "        nn_scores.append(nn_score)\n",
    "        if llm_score > nn_score:\n",
    "            sum0 += 1\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            sum1 += 1\n",
    "            labels.append(1)\n",
    "\n",
    "    print(total_llm_score, total_nn_score)\n",
    "    print(total_llm_time_cost, total_nn_time_cost)\n",
    "    print(sum0, sum1)\n",
    "\n",
    "    allocation_df = pd.DataFrame({\"Text\": texts, \"Feature\": features, \"Label\": labels, \"LLM_time_cost\": llm_time_costs, \"NN_time_cost\": nn_time_costs, \"LLM_score\": llm_scores, \"NN_score\": nn_scores})\n",
    "\n",
    "    return allocation_df\n",
    "\n",
    "allocation_df = generate_allocation_data(sum0, sum1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f403b1f9-58f1-490a-ba7d-da4d225f9a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------67----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6824413976116762\n",
      "system: 380.18348698402406 2933.126845598221\n",
      "best: 408.664289386943 2134.284155368805\n",
      "llm: 378.2113728513068 3307.418973684311\n",
      "nn: 292.896293444559 950.8068039417267\n",
      "----------------------68----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6629809818664307\n",
      "system: 379.04171503707767 2870.627744436264\n",
      "best: 409.2718108519912 2135.3852078914642\n",
      "llm: 377.17198260873556 3085.3264033794403\n",
      "nn: 296.98885338008404 940.2483470439911\n",
      "----------------------69----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6638655462184874\n",
      "system: 373.5245298621303 2976.4405405521393\n",
      "best: 406.07065110094845 2082.459053993225\n",
      "llm: 371.18498994680704 3385.6143465042114\n",
      "nn: 295.1798997335136 936.712233543396\n"
     ]
    }
   ],
   "source": [
    "seed = 67\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"----------------------{i}----------------------\")\n",
    "    train_df, test_df = train_test_split(allocation_df, test_size=0.2, random_state=seed + i)\n",
    "    X_train, X_test, y_train, y_test, llm_scores, nn_scores, llm_time_costs, nn_time_costs = train_df['Feature'].to_list(), test_df['Feature'].to_list(), train_df['Label'].to_list(), test_df['Label'].to_list(), test_df['LLM_score'].to_list(), test_df['NN_score'].to_list(), test_df['LLM_time_cost'].to_list(), test_df['NN_time_cost'].to_list()\n",
    "\n",
    "    print(X_train)\n",
    "    pca = PCA(n_components=50)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "    # 将测试集应用于相同的 PCA 转换\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # 实例化 SVM 分类器，并用 PCA 降维后的训练集进行拟合\n",
    "    svm = SVC(C=0.1, kernel='rbf')\n",
    "    svm.fit(X_train_pca, y_train)\n",
    "\n",
    "    # 预测测试集\n",
    "    y_pred = svm.predict(X_test_pca)\n",
    "\n",
    "    # 计算准确度\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    total_score, total_time_cost = 0, 0\n",
    "    for pred, llm_score, nn_score, llm_time_cost, nn_time_cost in zip(y_pred, llm_scores, nn_scores, llm_time_costs, nn_time_costs):\n",
    "        if pred == 0:\n",
    "            total_score += llm_score.item()\n",
    "            total_time_cost += llm_time_cost\n",
    "        else:\n",
    "            total_score += nn_score.item()\n",
    "            total_time_cost += nn_time_cost\n",
    "    print(\"system:\", total_score, total_time_cost)\n",
    "\n",
    "    total_score, total_time_cost = 0, 0\n",
    "    for truth, llm_score, nn_score, llm_time_cost, nn_time_cost in zip(y_test, llm_scores, nn_scores, llm_time_costs, nn_time_costs):\n",
    "        if truth == 0:\n",
    "            total_score += llm_score.item()\n",
    "            total_time_cost += llm_time_cost\n",
    "        else:\n",
    "            total_score += nn_score.item()\n",
    "            total_time_cost += nn_time_cost\n",
    "    print(\"best:\", total_score, total_time_cost)\n",
    "\n",
    "    total_score, total_time_cost = 0, 0\n",
    "    for llm_score, llm_time_cost in zip(llm_scores, llm_time_costs):\n",
    "        total_score += llm_score.item()\n",
    "        total_time_cost += llm_time_cost\n",
    "    print(\"llm:\", total_score, total_time_cost)\n",
    "\n",
    "    total_score, total_time_cost = 0, 0\n",
    "    for nn_score, nn_time_cost in zip(nn_scores, nn_time_costs):\n",
    "        total_score += nn_score.item()\n",
    "        total_time_cost += nn_time_cost\n",
    "    print(\"nn:\", total_score, total_time_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae20939-07d8-461d-83a0-fcd64f5276a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
